{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem definition\n",
    "\n",
    "We wish to minimize\n",
    "\n",
    "$$ I(u,v) = \\frac{\\theta}{2} \\int_{\\omega} Q_2(\\nabla_s u + \\tfrac{1}{2} \\nabla v \\otimes \\nabla v) \\mathrm{d}x\n",
    "   + \\frac{1}{24} \\int_{\\omega} Q_2(\\nabla^2 v - B) \\mathrm{d}x, $$\n",
    "\n",
    "with $B \\in \\mathbb{R}^{2 \\times 2}$, e.g. the identity matrix, and $Q_2$ a quadratic form, e.g. (isotropic material):\n",
    "\n",
    "$$ Q_2 (F) = 2 \\mu | \\operatorname{sym} F |^2 + \\frac{2 \\mu \\lambda}{2 \\mu + \\lambda}\n",
    "   \\operatorname{tr}^2 F, \\quad F \\in \\mathbb{R}^{2 \\times 2}, $$\n",
    "\n",
    "or, for a specific choice of constants, the simpler $Q_2(F) = |F|^2$.\n",
    "  \n",
    "We work in $P_1$ with the constraints of zero mean and zero mean antisymmetric gradient. Because we only have $C^0$ elements we set $z$ for $\\nabla v$ and minimize instead\n",
    "\n",
    "$$ J(u,z) = \\frac{\\theta}{2} \\int_{\\omega} Q_2(\\nabla_s u + \\tfrac{1}{2} z \\otimes z) \\mathrm{d}x \n",
    "          + \\frac{1}{24} \\int_{\\omega} Q_2\\nabla z - B) \\mathrm{d}x \n",
    "          + \\mu_\\epsilon \\int_{\\omega} |\\mathrm{curl}\\ z|^{2} \\mathrm{d}x, $$\n",
    "\n",
    "then recover the vertical displacements (up to a constant) by minimizing\n",
    "\n",
    "$$ F(p,q) = \\tfrac{1}{2} || \\nabla p - q ||^2 + \\tfrac{1}{2} || q - z ||^2. $$\n",
    "\n",
    "This we do by solving the linear problem $D F = 0$.\n",
    "\n",
    "Minimization of the energy functional $J$ is done via gradient descent and a line search. In particular, at each timestep we compute $d_t w \\in W $ such that for all $\\tau \\in W$:\n",
    "\n",
    "$$ (d_t w, \\tau)_{H^1_0 \\times H^2_0} = -DJ(w_t)[\\tau] $$\n",
    "\n",
    "Note that it is essential to use the full scalar product (or the one corresponding to the seminorms? check this) or we run into issues at the boundaries (to see this start with zero displacements and integrate by parts).(Also: the proper Riesz representative will only be obtained with correct scalar product).\n",
    "\n",
    "A decoupled gradient descent in each component does not work, probably because the functional is not separately convex (see Bartels' book, p. 110, remark (iv)).\n",
    "\n",
    "In plane displacements and gradients of out of plane displacements form a mixed function space $U \\times Z$. We also have another scalar space $V$ where the potential of the out of plane gradients lives. The model is defined and solved in `run_model()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the range of $\\theta$\n",
    "\n",
    "We connect to the experiments database, then query it for the experiments we are interested in and convert the collection of objects returned into a pandas dataframe, then plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "from incense import ExperimentLoader\n",
    "\n",
    "loader = ExperimentLoader(mongo_uri='mongo:27017', db_name='lvk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiments can be searched by single config key, sorted and inspected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = sorted(loader.find_by_config_key(\"theta\", 11), key=lambda e: e.id)\n",
    "[e.config['projection'] for e in ee if e.config['init'] == 'ani_parab']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to query by multiple fields, so we add this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_by_config_keys(loader, _name=None, _status=None, **kwargs):\n",
    "    \"\"\" Assembles a mongo query to filter results by multiple config keys simultaneously. \"\"\"\n",
    "    terms = []\n",
    "    if _status:\n",
    "        terms.append({\"status\": _status})\n",
    "    if _name:\n",
    "        terms.append({\"experiment.name\": _name})\n",
    "    query = {\"$and\": terms}\n",
    "    for k, v in kwargs.items():\n",
    "        k = 'config.' + k\n",
    "        terms.append({k: v})\n",
    "    return loader.find(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assemble a list of experiments related by initial condition, mesh type and whether projections onto constraint spaces are made or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_last(ss):\n",
    "    return ss[-10:].mean()\n",
    "\n",
    "names = [\"0b94093\", \"652558c\"]  # [None] for all experiments \n",
    "inits = [\"ani_parab\"]  # [\"zero\", \"ani_parab\", \"ani_compression\"]\n",
    "mesh_types = [\"circle\"]  #[\"circle\", \"rectangle\"]\n",
    "projections = [True]  # [True, False]\n",
    "\n",
    "results = []\n",
    "labels = []\n",
    "for name in names:\n",
    "    for init in inits:\n",
    "        for mesh_type in mesh_types:\n",
    "            for projection in projections:            \n",
    "                experiments = find_by_config_keys(loader, _name=name, _status=\"COMPLETED\",\n",
    "                                                  init=init, mesh_type=mesh_type,\n",
    "                                                  projection=projection)\n",
    "                try:\n",
    "                    df = experiments.project(on=[\"config.theta\",\n",
    "                                                 \"config.mu_scale\",\n",
    "                                                 \"config.skip\",\n",
    "                                                 \"config.max_steps\",\n",
    "                                                 \"start_time\",\n",
    "                                                 \"stop_time\",\n",
    "                                                 {\"metrics.J\": average_last,\n",
    "                                                 \"metrics.symmetry\": average_last,\n",
    "                                                 \"metrics.constraint\": average_last,\n",
    "                                                 \"metrics.Kxx\": average_last,\n",
    "                                                 \"metrics.Kxy\": average_last,\n",
    "                                                 \"metrics.Kyy\": average_last,\n",
    "                                                 \"metrics.alpha\": len}])\n",
    "\n",
    "                    df['duration'] = df['stop_time'] - df['start_time']\n",
    "                except KeyError:\n",
    "                    continue\n",
    "                    \n",
    "                label = \"_\".join((str(name), init, mesh_type, \"proj\" if projection else \"no-proj\"))\n",
    "                \n",
    "                unique_columns = [\"config.mu_scale\", \"config.hmin_power\", \"config.mesh_m\", \"config.mesh_n\"]\n",
    "                tmp = experiments.project(on=unique_columns)\n",
    "                for col in (s.split('.')[1] for s in unique_columns):\n",
    "                    cnt = tmp[col].unique().shape[0]\n",
    "                    if cnt > 1:\n",
    "                        print(\"WARNING Column '%s' has multiple (%d) values in '%s'!\" % (col, cnt, label))\n",
    "\n",
    "                print(\"Collected %d experiments in %s\" % (len(df), label))\n",
    "\n",
    "                # HACK: there is probably a better way of counting (and I could use df.rename())\n",
    "                df['steps'] = df['alpha_len']\n",
    "                if df['alpha_len'].mean() < 1000:\n",
    "                    df['steps'] *= df['skip']\n",
    "                    \n",
    "                df = df.drop(['start_time', 'stop_time', 'alpha_len', 'skip'], axis=1)\n",
    "                df = df.sort_values(by=['theta'])\n",
    "                \n",
    "                results.append(df)\n",
    "                labels.append(label)\n",
    "\n",
    "                del experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symmetry of the minimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 0   # First item to consider in all series\n",
    "fs = 22  # Base font size for plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with our simple definition of symmetry which simply computes the quotient of the two principal axes of the deformed disc or the diagonals of the deformed square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(16, 11))\n",
    "for res, label in zip(results, labels):\n",
    "    n = len(res)\n",
    "    #n = np.searchsorted(res['theta'], 4)\n",
    "    pl.plot(res['theta'][m:n], res['symmetry_average_last'][m:n], marker='.', label=label)\n",
    "pl.hlines(1, res['theta'][m:n].min(), res['theta'][m:n].max(), colors='r', linestyles=\"dotted\", )\n",
    "pl.xlabel('$\\\\theta$', fontsize=fs)\n",
    "pl.ylabel('Symmetry', fontsize=fs)\n",
    "if len(results) == 1:\n",
    "    pl.title(labels[0], fontsize=fs-4)\n",
    "else:\n",
    "    pl.legend(fontsize=fs-4)\n",
    "pl.tick_params(axis='both', which='major', labelsize=fs)\n",
    "pl.savefig('theta-symmetry-fine-mesh.eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With increasing $\\theta$ we expect the symmetry of the solution to be ever more violated until it is cylindrical rather than parabolic. We see a sharp increase around $\\theta = 40$. Note that this could mean little since\n",
    "\n",
    "* We use a poor criterion for symmetry (we are just taking the quotient of the principal axes)\n",
    "* Used solutions are not necessarily minima (gradient descent might not converge to $\\epsilon_{\\text{stop}}$ precision)\n",
    "\n",
    "To complete the picture above we plot the mean principal strains over the surface as a proxy for curvature. Ideally, we will observe a branching at the same point as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pl.figure(figsize=(16,11))\n",
    "for res, label in zip(results, labels):\n",
    "    n = len(res)  # np.searchsorted(res['theta'], 25)\n",
    "    label = \"\" if len(results) == 1 else \"-\" + label\n",
    "    pl.plot(res['theta'][m:n], res['Kxx_average_last'][m:n], marker='.', linewidth=3, label=\"$K_{xx}$\" + label)\n",
    "    pl.plot(res['theta'][m:n], res['Kyy_average_last'][m:n], marker='.', linewidth=3, label=\"$K_{yy}$\" + label)\n",
    "    \n",
    "pl.xlabel('$\\\\theta$', fontsize=fs)\n",
    "pl.ylabel('Principal strains', fontsize=fs)\n",
    "pl.legend(fontsize=fs-4)\n",
    "pl.tick_params(axis='both', which='major', labelsize=fs)\n",
    "if len(results) == 1:\n",
    "    pl.title(labels[0], fontsize=fs-4)\n",
    "pl.savefig('theta-strains.eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The $curl$ constraint "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an indication of the quality of the iterations, we can track how much the constraint $\\mu_\\epsilon \\int_{\\omega} |\\mathrm{curl}\\ z|^{2} \\mathrm{d}x$ is violated. Note that with the choice $\\mu_\\epsilon = 1/\\epsilon^\\alpha$, the finer the mesh, stronger the penalty on $z$ for not being a gradient. However, we must keep $\\mu_\\epsilon = o(\\epsilon^{-2})$ as $\\epsilon \\rightarrow \\infty$ in order for the proof of $\\Gamma$-convergence to hold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(16, 11))\n",
    "for res, label in zip(results, labels):\n",
    "    n = len(res)\n",
    "    #m = np.searchsorted(res['theta'], 25)\n",
    "    #n = np.searchsorted(res['theta'], 200)\n",
    "    pl.plot(res['theta'][m:n], res['constraint_average_last'][m:n]*1e4, marker='.', label=label)\n",
    "pl.hlines(0, res['theta'][m:n].min(), res['theta'][m:n].max(), colors='r', linestyles=\"dotted\")\n",
    "pl.xlabel('$\\\\theta$', fontsize=fs)\n",
    "pl.ylabel('$|curl|*10^4$', fontsize=fs)\n",
    "if len(results) == 1:\n",
    "    pl.title(labels[0], fontsize=fs-4)\n",
    "else:\n",
    "    pl.legend(fontsize=fs-4)\n",
    "pl.tick_params(axis='both', which='major', labelsize=fs)\n",
    "pl.savefig('theta-curl.eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational cost\n",
    "\n",
    "As a poor-man's proxy of a proper empirical analysis of the convergence rate, we plot the duration of the experiments. This can help identify bogus runs, e.g. for having reached the maximum number of steps in too little time. Of particular interest are those where the maximum number of iterations was reached. We mark them with a cross:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(16,11))\n",
    "minh, maxh = np.inf, 0\n",
    "for res, label in zip(results, labels):\n",
    "    n = len(res)\n",
    "    steps = res['steps'][m:n]\n",
    "    max_steps = res['max_steps'][m:n]\n",
    "    seconds = res['duration'][m:n].astype('timedelta64[s]')\n",
    "    minh, maxh = min(minh, int(seconds.min()//3600)), max(maxh, int(seconds.max()//3600+1))\n",
    "    pl.plot(res['theta'][m:n], seconds, marker='.', label=label)\n",
    "    pl.scatter(res['theta'][m:n][steps == max_steps], seconds[steps == max_steps], marker='x', s=80, label=None)\n",
    "pl.xlabel('$\\\\theta$', fontsize=fs)\n",
    "\n",
    "pl.ylabel('Duration (hours)', fontsize=fs)\n",
    "\n",
    "pl.yticks(ticks=[3600*h for h in range(minh, maxh, 2)], labels=range(minh, maxh, 2))\n",
    "b, t = pl.ylim()\n",
    "pl.ylim(b, t+1)\n",
    "pl.legend()\n",
    "if len(results) == 1:\n",
    "    pl.title(labels[0], fontsize=fs-4)\n",
    "else:\n",
    "    pl.legend(fontsize=fs-4)\n",
    "pl.tick_params(axis='both', which='major', labelsize=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the number of steps directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(16,11))\n",
    "for res, label in zip(results, labels):\n",
    "    n = len(res)\n",
    "    steps = res['steps'][m:n]\n",
    "    max_steps = res['max_steps'][m:n]\n",
    "    pl.plot(res['theta'][m:n], steps, marker='.', label=label)\n",
    "    pl.scatter(res['theta'][m:n][steps == max_steps], steps[steps == max_steps], marker='x', s=80, label=None)\n",
    "pl.xlabel('$\\\\theta$', fontsize=fs)\n",
    "pl.ylabel('Number of steps', fontsize=fs)\n",
    "if len(results) == 1:\n",
    "    pl.title(labels[0], fontsize=fs-4)\n",
    "else:\n",
    "    pl.legend(fontsize=fs-4)\n",
    "pl.tick_params(axis='both', which='major', labelsize=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the final configuration for increasing $\\theta$\n",
    "\n",
    "The function `gather_last_timesteps()` traverses all output files for an experiment and creates a ParaView file for visualisation with the last frame of each run (i.e. for all values of $\\theta$. Open with ParaView to examine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import gather_last_timesteps\n",
    "\n",
    "gather_last_timesteps('../output', '652558c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some examples to query the database\n",
    "\n",
    "Here are a few recipes to query and manipulate objects in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exps = loader.find({\"$and\": [{\"config.theta\": {\"$lt\": 20}}, {\"experiment.name\": \"9abcdef\"}]})\n",
    "\n",
    "# Careful!! `find_by_key` interprets strings as regexes!!!\n",
    "exps = loader.find_by_key(\"experiment.name\", \"^some name here$\")\n",
    "print(len(exps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting experiments is simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in exps:\n",
    "    e.delete() #confirmed=True) # to skip confirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also interact with MongoDB using the console and mongo commands. From a shell, having the containers up, run:\n",
    "```shell\n",
    "docker exec -it lvk_mongo_1 mongo\n",
    "```\n",
    "\n",
    "Then from the console you can access the experiments database:\n",
    "```\n",
    "> use lvk\n",
    "> db.runs.update({\"experiment.name\": \"ee40d72\"}, {$set: {\"experiment.name\": \"some descriptive name\"}}, {multi: true})\n",
    "```\n",
    "\n",
    "Note however that manipulating runs in this manner requires manually taking care of artifacts and other related bits of information. `incense` does this for us and deletes unnecessary files and objects from the DB when we delete experiments.\n",
    "\n",
    "Finally, [pymongo](https://api.mongodb.com/python/current/) is also installed in the container and can be used instead of the console."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {
    "height": "132px",
    "width": "274px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
